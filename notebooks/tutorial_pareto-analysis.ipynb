{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from paretoset import paretoset\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../usecase_cd')\n",
    "sys.path.append('../qnetsur')\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "\n",
    "font = 16\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'font.family': 'arial',\n",
    "    'font.size': font,\n",
    "    'axes.labelsize': font,  \n",
    "    'xtick.labelsize': font,  \n",
    "    'ytick.labelsize': font, \n",
    "    'legend.fontsize': font,\n",
    "    'legend.title_fontsize': font,\n",
    "    'axes.titlesize': font\n",
    "})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Analysis of collected Pareto frontier \n",
    "\n",
    "This notebook serves as tutorial for analysing solutions for multiple-optimization objectives (=Pareto frontier).\n",
    "1. We will look into how we can retrieve these solutions of a random 2D sample set.\n",
    "2. We will investigate \n",
    "* our smallest network topology, the **(2,1)-tree**, and two random tree networks\n",
    "* a random **20-node tree network**\n",
    "* a random **100-node tree network**\n",
    "\n",
    "\n",
    "BUT BEFORE START, download [TU4LINK] and set the folder path to\n",
    "\n",
    "`folder3n = /path/to/QENTSUR-DATA/continuous_distribution_protocols/notebook_cd_n3/`\n",
    "\n",
    "`folder20n = /path/to/QENTSUR-DATA/continuous_distribution_protocols/notebook_cd_n20/`\n",
    "\n",
    "`folder100n = /path/to/QENTSUR-DATA/continuous_distribution_protocols/cd_1h/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder3n = '/Users/localadmin/Documents/git/surdata/QENTSUR-DATA/continuous_distribution_protocols/notebook_cd_n3/'\n",
    "folder20n = '/Users/localadmin/Documents/git/surdata/QENTSUR-DATA/continuous_distribution_protocols/notebook_cd_n20/'\n",
    "folder100n = '/Users/localadmin/Documents/git/surdata/QENTSUR-DATA/continuous_distribution_protocols/cd_10h/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Pareto front of a random 2D sample set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 1\n",
    "sample = (b-a) * np.random.random_sample((2,100)) + a\n",
    "plt.scatter(x=sample[0], y=sample[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pareto frontier of the collected sample can be easiliy retrieved with `paretoset()` an algorithm implemented by [Tommy Otland, 2021](https://tommyodland.com/articles/2020/pareto-non-dominated-front-as-a-consumer-strategy/#notes-and-references) and is marked in orange below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = paretoset(sample.T, sense=[\"max\", \"max\"])\n",
    "fig, ax = plt.subplots(figsize=[3,3])\n",
    "plt.ylabel('Objective 2')\n",
    "plt.xlabel('Objective 1')\n",
    "plt.scatter(x=sample[0], y=sample[1], label=r'$\\in \\mathcal{S}\\setminus \\mathcal{S}_{dom}$', marker='x')\n",
    "plt.scatter(x=sample[0][filter], y=sample[1][filter], label=r'$\\in \\mathcal{S}_{dom}$', s=60)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.tight_layout()\n",
    "#plt.savefig('simple-pareto.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pareto analysis of (2,1)-tree of collected solution set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "T = nx.balanced_tree(2, 1)\n",
    "\n",
    "pos = graphviz_layout(T, prog=\"twopi\")\n",
    "nx.draw(T, pos, with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load result data from the online storage as mentioned above or run `python surrogate.py --topo tree-2-1 --level --iterator 30 ` (45 min runtime). `config.py` is set with the following parameters\n",
    "\n",
    "* 'protocol': 'ndsrs',\n",
    "* 'p_gen': 0.9,\n",
    "* 'p_swap': 1,\n",
    "* 'return_data': 'avg',\n",
    "* 'progress_bar': None,\n",
    "* 'total_time': 1000,\n",
    "* 'N_samples': 1000,\n",
    "* 'p_cons': 0.225,\n",
    "* 'qbits_per_channel': 5,\n",
    "* 'cutoff': 28,\n",
    "* 'M': 2,\n",
    "* 'A': array([[0, 1, 1],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder3n+'SU_tree-2-1_100cycles_SEED42_06-26-2024_16:30:08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df[['SVR', 'DecisionTree']].apply(pd.unique).plot()\n",
    "plt.xlabel('Optimization Cycle')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "#plt.savefig('cd_tree-2-1_mlbenchmarks.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excursion: How to calculate which cutoff time to set (given total runtime $T$, $M$, $F_\\mathrm{new}$ and $F_\\mathrm{app}$ according to [Inesta et al.,2023](https://journals.aps.org/pra/abstract/10.1103/PhysRevA.108.052615))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1000\n",
    "M = 4\n",
    "Fnew = 0.888\n",
    "Fapp = 0.6\n",
    "-T*np.log( 3/(4*Fnew-1) * ((4*Fapp-1)/3)**(1/M) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_neighbors = df[df.columns[df.columns.str.fullmatch('\\d+')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again calculate the Pareto frontier of the collected set $S_\\mathrm{Parto}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn = virtual_neighbors.to_numpy()\n",
    "filter = paretoset(vn, sense=[\"max\"]*3)\n",
    "print(len(filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,sharey=False, sharex=False, figsize=[5,6])\n",
    "labels = [1,0,2,1]\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.scatter(x=vn[:,labels[i]], y=vn[:,labels[i+1]])\n",
    "    ax.scatter(x=vn[:,labels[i]][filter], y=vn[:,labels[i+1]][filter])\n",
    "    ax.set_xlabel(f'User {labels[i]}')\n",
    "    ax.set_ylabel(f'User {labels[i+1]}')\n",
    "    ax.set_ylim([0,2])\n",
    "    ax.set_xlim([0,2])\n",
    "    ax.grid()\n",
    "axs[0].set_title('Virtual Neighbors per User')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as 3D version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "virtual_neighbors['filter'] = filter\n",
    "fig = px.scatter_3d(virtual_neighbors, x=virtual_neighbors.columns[0], y=virtual_neighbors.columns[1], z=virtual_neighbors.columns[2],\n",
    "              color='filter')\n",
    "plt.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will plot the distribution of the probability values in $S_\\mathrm{Parto}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df[df.columns[df.columns.str.contains('q_swap')]]\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "g = sns.boxplot(X_df[filter], palette=['tab:orange'])\n",
    "g.set_xticklabels(['User 0', 'User 1,2'])\n",
    "plt.ylabel(r'$q_{swap}$')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('cd-21tree-pareto.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the parameter distribution in the dominating set pretty much coveres the optimal aggregated behaviour of the simulation (in terms of achieved virtual neighbors for each user):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(250, 30, l=65, center=\"dark\", as_cmap=True)\n",
    "df_plot = pd.read_pickle('../../surdata/cd_n3/tree-2-1-heatmap.pkl')\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.heatmap(df_plot, cmap=cmap, cbar_kws={'label': 'Aggregated Virtual Neighbors'})\n",
    "plt.xlabel(r'$q_{swap,1}$')\n",
    "plt.ylabel(r'$q_{swap,0}$')\n",
    "plt.yticks(rotation=0) \n",
    "plt.xticks(rotation=45) \n",
    "plt.tight_layout()\n",
    "plt.savefig('cd-21tree-heatmap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df_ks_norm = X_df[filter].apply(lambda x: stats.kstest(x, stats.norm.cdf)[0])\n",
    "df_ks_uniform = X_df[filter].apply(lambda x: stats.kstest(x, stats.uniform.cdf)[0])\n",
    "df_plot = pd.concat([df_ks_norm, df_ks_uniform], axis=1).reset_index()\n",
    "df_plot.columns = ['q_swap','normal', 'uniform']\n",
    "sns.scatterplot(df_plot)\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('KS statistic')\n",
    "plt.xlabel('q_swap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will go to a larger layout, a random **20-node tree network** involving 7 users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "graph = nx.random_tree(n, seed=7)\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "pos = nx.spring_layout(graph, scale=2, seed=3)\n",
    "colors = ['lightgrey'] * n\n",
    "nx.draw(graph, pos, with_labels=True, node_color=colors, node_size=300)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cd-random-tree20-pareto-graph-plain.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the result data of the surrogate optimization (or execute it with according parameters) and again retrieve the dominating set from the collected training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder20n+'SU_randtree-20_100cycles_SEED42_06-26-2024_13:25:43.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.astype('str')\n",
    "vn = df[df.columns[df.columns.str.fullmatch('\\d+')]]\n",
    "df_q = df[df.columns[df.columns.str.contains('q_swap')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the following values for the overall virtual neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... from which we retrieve the dominating set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pareto_frontier(vn, q_set):\n",
    "    vn_to_analyse = vn\n",
    "    filter = paretoset(vn_to_analyse, sense=[\"max\"]*vn_to_analyse.shape[1])\n",
    "    return q_set[filter], sum(filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(this can take a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_filtered, size = get_pareto_frontier(vn, df_q)\n",
    "size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the overall distribution of swap probability values in the dominating set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "df_melted = df_q_filtered.melt(var_name='Node', value_name='Probability')\n",
    "df_melted['Node Degree'] = df_melted['Node'].apply(lambda x: graph.degree[int(re.sub(r\"\\D\", \"\", x))])\n",
    "df_melted_sorted = df_melted.sort_values('Node Degree')\n",
    "df_melted_sorted[['Node Degree', 'Probability']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "cmap =  light_orange_palette = sns.light_palette('tab:orange', n_colors=10, reverse=False, as_cmap=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = [7,4])\n",
    "sns.pointplot(df_melted_sorted, x='Node', y='Probability', errorbar='pi', ax=ax, linestyles='', color='tab:orange')#{node: cmap(val) for node, val in dict(df_q_filtered.mean()).items()}, )\n",
    "plt.xlabel('Node')\n",
    "labels = [re.sub('\\D', '', label.get_text()) for label in ax.get_xticklabels()]\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "plt.ylabel(r'$q_{swap}$')\n",
    "plt.grid()\n",
    "plt.ylim([0,1])\n",
    "plt.tight_layout()\n",
    "plt.savefig('cd-random-tree20-pareto.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "pos = nx.spring_layout(graph, scale=2, seed=3)\n",
    "colors = ['lightgrey'] * n\n",
    "for idx in labels:\n",
    "    colors[int(idx)] = cmap(df_q_filtered['q_swap'+idx].mean()) if df_q_filtered['q_swap'+idx].std() <= 0.1 else 'lightblue'\n",
    "nx.draw(graph, pos, with_labels=True, node_color=colors, node_size=300)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin = 0, vmax=1))\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(r'$q_{swap}$', labelpad=15, rotation=270)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cd-random-tree20-pareto-graph.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df_ks_norm = df_q_filtered.apply(lambda x: stats.kstest(x, stats.norm.cdf)[0])\n",
    "df_ks_uniform = df_q_filtered.apply(lambda x: stats.kstest(x, stats.uniform.cdf)[0])\n",
    "df_plot = pd.concat([df_ks_norm, df_ks_uniform], axis=1).reset_index()\n",
    "df_plot.columns = ['Node', 'normal', 'uniform']\n",
    "df_plot_sorted = df_melted_sorted.merge(df_plot, how='left', on='Node')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = [7,4])\n",
    "sns.pointplot(df_plot_sorted, x='Node', y='Probability', errorbar='pi', ax=ax, linestyles='', color='tab:orange')#{node: cmap(val) for node, val in dict(df_q_filtered.mean()).items()}, )\n",
    "sns.pointplot(df_plot_sorted, x='Node', y='normal', ax=ax, linestyles='')\n",
    "sns.pointplot(df_plot_sorted, x='Node', y='uniform', ax=ax, linestyles='', color='green')\n",
    "plt.xlabel('Node')\n",
    "labels = [re.sub('\\D', '', label.get_text()) for label in ax.get_xticklabels()]\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "plt.ylabel(r'$q_{swap}$')\n",
    "plt.grid()\n",
    "plt.ylim([0,1])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and the axes\n",
    "fig, ax = plt.subplots(figsize=[7, 4])\n",
    "\n",
    "# Plotting the 'Probability' data on the first y-axis\n",
    "sns.pointplot(data=df_plot_sorted, x='Node', y='Probability', errorbar='pi', ax=ax, linestyles='', color='tab:orange', label=r'$q_{swap}$')\n",
    "\n",
    "# Create a second y-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plotting 'normal' and 'uniform' on the second y-axis\n",
    "sns.pointplot(data=df_plot_sorted, x='Node', y='normal', ax=ax2, linestyles='', color='tab:blue', label='KS to Normal')\n",
    "sns.pointplot(data=df_plot_sorted, x='Node', y='uniform', ax=ax2, linestyles='', color='tab:green', label='KS to Uniform')\n",
    "\n",
    "# Customizing the left y-axis to be orange\n",
    "ax.spines['left'].set_color('tab:orange')\n",
    "ax.yaxis.label.set_color('tab:orange')\n",
    "ax.tick_params(axis='y', colors='tab:orange')\n",
    "\n",
    "# Labeling axes\n",
    "ax.set_xlabel('Node')\n",
    "ax.set_ylabel(r'$q_{swap}$')\n",
    "ax2.set_ylabel('KS statistic')\n",
    "# Adjusting the tick labels for readability\n",
    "labels = [re.sub('\\D', '', label.get_text()) for label in ax.get_xticklabels()]\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "# Adding a legend to differentiate the plots\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left', bbox_to_anchor=(1.2, 1))\n",
    "ax.legend(lines + lines2, labels + labels2, loc='upper left', bbox_to_anchor=(1.2, 1))\n",
    "\n",
    "# Set limits for the y-axes\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Adding grid and layout adjustments\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last layout we will investigate is a **100-node network** involing 39 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "graph = nx.random_tree(n, seed=7)\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "pos = nx.spring_layout(graph, scale=2, seed=3)\n",
    "colors = ['lightgrey'] * n\n",
    "nx.draw(graph, pos, with_labels=True, node_color=colors, node_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(folder100n+'SU*.csv')\n",
    "dfs = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, index_col=0)\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "vn = df[df.columns[df.columns.astype('str').str.fullmatch('\\d+')]]\n",
    "df_q = df[df.columns[df.columns.astype('str').str.contains('q_swap')]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again retrieve the dominating set (can take a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_filtered, size = get_pareto_frontier(vn, df_q)\n",
    "size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most distributions are widely spread with a sd above 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_filtered.std(axis=0)[df_q_filtered.std(axis=0) < 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap =  light_orange_palette = sns.light_palette('tab:orange', n_colors=10, reverse=False, as_cmap=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = [7,4])\n",
    "sns.pointplot(df_q_filtered[df_q_filtered.columns[df_q_filtered.std(axis=0) < 0.2]], palette={'tab:orange'}, errorbar='sd', ax=ax)#{node: cmap(val) for node, val in dict(df_q_filtered.mean()).items()}, )\n",
    "plt.xlabel('Node')\n",
    "labels = [re.sub('\\D', '', label.get_text()) for label in ax.get_xticklabels()]\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "plt.ylabel(r'$q_{swap}$')\n",
    "plt.grid()\n",
    "plt.ylim([0,1])\n",
    "plt.tight_layout()\n",
    "plt.savefig('cd-random-tree100-pareto.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, let's look at the best found solution of the largest dataset (since we cannot gain too much insight from the Pareto set anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvals = df_q.iloc[vn.sum(axis=1).argmax()]\n",
    "print(qvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "pos = nx.spring_layout(graph, scale=2, seed=2)\n",
    "graph = nx.random_tree(n, seed=7)\n",
    "nx.draw(graph, pos= pos, node_size=50, node_color='grey')\n",
    "plt.savefig('plaintree100.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmap =  sns.light_palette('tab:orange', n_colors=10, reverse=False, as_cmap=True)\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "pos = nx.spring_layout(graph, scale=2, seed=2)\n",
    "colors = [cmap(qswap_mean) for qswap_mean in qvals]\n",
    "labels = {node: round(val,1) for node, val in enumerate(qvals)}\n",
    "nx.draw(graph, pos, with_labels=False, node_color=colors, node_size=300)\n",
    "nx.draw_networkx_labels(graph, pos, labels=labels)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin = 0, vmax=1))\n",
    "plt.title(r'Best Found Solution with Time Limit $T = 10$ h')\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(r'$q_{swap}$', labelpad=15, rotation=270)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cd-random-tree-best.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df_ks_norm = df_q_filtered.apply(lambda x: stats.kstest(x, stats.norm.cdf)[0])\n",
    "df_ks_uniform = df_q_filtered.apply(lambda x: stats.kstest(x, stats.uniform.cdf)[0])\n",
    "df_plot = pd.concat([df_ks_norm, df_ks_uniform], axis=1).reset_index()\n",
    "df_plot.columns = ['Node', 'normal', 'uniform']\n",
    "\n",
    "df_melted = df_q_filtered.melt(var_name='Node', value_name='Probability')\n",
    "df_melted['Node Degree'] = df_melted['Node'].apply(lambda x: graph.degree[int(re.sub(r\"\\D\", \"\", x))])\n",
    "df_melted_sorted = df_melted.sort_values('Node Degree')\n",
    "df_plot_sorted = df_melted_sorted.merge(df_plot, how='left', on='Node')\n",
    "\n",
    "# Create the figure and the axes\n",
    "fig, ax = plt.subplots(figsize=[30, 4])\n",
    "\n",
    "# Plotting the 'Probability' data on the first y-axis\n",
    "sns.pointplot(data=df_plot_sorted, x='Node', y='Probability', errorbar='pi', ax=ax, linestyles='', color='tab:orange', label=r'$q_{swap}$')\n",
    "\n",
    "# Create a second y-axis\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plotting 'normal' and 'uniform' on the second y-axis\n",
    "sns.pointplot(data=df_plot_sorted, x='Node', y='normal', ax=ax2, linestyles='', color='tab:blue', label='KS to Normal')\n",
    "sns.pointplot(data=df_plot_sorted, x='Node', y='uniform', ax=ax2, linestyles='', color='tab:green', label='KS to Uniform')\n",
    "\n",
    "# Customizing the left y-axis to be orange\n",
    "ax.spines['left'].set_color('tab:orange')\n",
    "ax.yaxis.label.set_color('tab:orange')\n",
    "ax.tick_params(axis='y', colors='tab:orange')\n",
    "\n",
    "# Labeling axes\n",
    "ax.set_xlabel('Node')\n",
    "ax.set_ylabel(r'$q_{swap}$')\n",
    "ax2.set_ylabel('KS statistic')\n",
    "# Adjusting the tick labels for readability\n",
    "labels = [re.sub('\\D', '', label.get_text()) for label in ax.get_xticklabels()]\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "\n",
    "# Adding a legend to differentiate the plots\n",
    "labels = [re.sub('\\D', '', label.get_text()) for label in ax.get_xticklabels()]\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "ax.legend(lines + lines2, labels + labels2, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "\n",
    "# Set limits for the y-axes\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Adding grid and layout adjustments\n",
    "plt.grid()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnetsur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
