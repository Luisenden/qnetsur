{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquisition and sampling\n",
    "\n",
    "Our surrogate method relies on machine learning model's predictions of randomly sampled data around promising points. This random data is sampled from truncated normal distributions which standard deviation gets narrower with each optimization cycle $t$.\n",
    "In this tutorial, we will also see how the exploration degree matters in the described endevour.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "\n",
    "font = 16\n",
    "plt.rcParams.update({\n",
    "    'text.usetex': False,\n",
    "    'font.family': 'arial',\n",
    "    'font.size': font,\n",
    "    'axes.labelsize': font,  \n",
    "    'xtick.labelsize': font,  \n",
    "    'ytick.labelsize': font, \n",
    "    'legend.fontsize': font,\n",
    "    'legend.title_fontsize': font,\n",
    "    'axes.titlesize': font\n",
    "})\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration vs. Exploitation \n",
    "\n",
    "Each optimization cycle decreases the standard deviation of normal distributions $\\mathcal{N}_{\\mathrm{trunc}}(\\mu_{p}, \\sigma_{p}(t))$ around each parameter value $\\mu_{p}=x_p$. This is done based on the current cycle $t$ of the optimization process. Thereby, the focus of discovering new, but less favorable configurations (exploration) gradually shifts towards refining known and well performing configurations (exploitation). To this end, the distribution is truncated at $x_p^\\mathrm{min}$ and $x_p^\\mathrm{max}$ with standard deviation $\\sigma_p(t) = \\gamma(t) \\cdot (x_p^{\\mathrm{max}}-x_p^\\mathrm{min})/2$, where $\\gamma(t)$ is a monotonically decreasing function for $0\\le t\\le T$ (see Proof \\ref{proof:gamma} below). Initially, $\\sigma_p(t=0) = (x_p^{\\mathrm{max}}-x_p^\\mathrm{min})/2$ and it gradually narrows as $\\gamma(t) > \\gamma(t+1)$. We use the smooth function\n",
    "\\begin{align}\n",
    "    \\gamma(t) = (1-\\ln(1+t/T)^2)^d,\\ \\text{where } d\\ge 1\n",
    "\\end{align} \n",
    "for this purpose, where $T$ is the maximum number of optimization cycles and $d$ is chosen according to the degree of exploitation desired; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1\n",
    "gamma = lambda count, d: (1-np.log(1+count/int(T))**2)**d\n",
    "x = np.linspace(0,T,100)\n",
    "for i,d in enumerate(range(0,8,2)):\n",
    "    plt.plot(x, [gamma(count,d) for count in x], label=f'd={d}', color=sns.color_palette()[i], ls=['-', '--', '-.', ':'][i])\n",
    "plt.legend()\n",
    "plt.ylabel(r'$\\gamma(t)$')\n",
    "plt.xlabel(r'$t/T$')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('transition_function.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume $d=4$ and we just started the surrogate optimization process $t=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "gamma(0,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, that we sample with the full standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the truncated normal distribution (from which we sample the points for the machine learning models) look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "xmin = 2\n",
    "xmax = 7\n",
    "x = 4\n",
    "std = gamma(0,d) * (xmax - xmin)/2\n",
    "sample = truncnorm.rvs((xmin - x) / std, (xmax+1 - x) / std, loc=x, scale=std, size=10000)\n",
    "sample = sample.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.hist(sample, bins=50)\n",
    "plt.xlim((0,9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume $d=4$ and the end of the optimization process is reached $t=T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=2\n",
    "gamma(1,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = gamma(1,d) * (xmax - xmin)/2\n",
    "sample = truncnorm.rvs((xmin - x) / std, (xmax+1 - x) / std, loc=x, scale=std, size=10000)\n",
    "sample = sample.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.hist(sample, bins=50)\n",
    "plt.xlim((0,9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 3, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[::-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, at $t=T$ sampling takes place much closer to the mean (current parameter value $x_p$)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnetsur",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
